{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":60897,"databundleVersionId":6563787,"sourceType":"competition"},{"sourceId":7139632,"sourceType":"datasetVersion","datasetId":4120529}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.metrics import f1_score, roc_auc_score\n\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nfrom joblib import dump, load\n\n\nf_path = \"/kaggle/input/d/miracl/kmaml223/\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-07T15:50:39.526529Z","iopub.execute_input":"2023-12-07T15:50:39.527611Z","iopub.status.idle":"2023-12-07T15:50:41.116456Z","shell.execute_reply.started":"2023-12-07T15:50:39.527533Z","shell.execute_reply":"2023-12-07T15:50:41.115471Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(f_path + \"train.csv\")\nprint(f\"Train shape: {train.shape}\")\nprint(f\"Train columns: {train.columns}\")\ntest = pd.read_csv(f_path + \"test.csv\")\nprint(f\"Test shape: {test.shape}\")\nprint(f\"Test columns: {test.columns}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:50:41.117954Z","iopub.execute_input":"2023-12-07T15:50:41.118386Z","iopub.status.idle":"2023-12-07T15:50:43.707872Z","shell.execute_reply.started":"2023-12-07T15:50:41.118354Z","shell.execute_reply":"2023-12-07T15:50:43.706602Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Train shape: (159571, 8)\nTrain columns: Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n       'insult', 'identity_hate'],\n      dtype='object')\nTest shape: (63978, 3)\nTest columns: Index(['Unnamed: 0', 'id', 'comment_text'], dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"with_labels = train[(train['toxic'] == 1) | (train['severe_toxic'] == 1) | (train['obscene'] == 1) | (train['threat'] == 1) | (train['insult'] == 1) | (train['identity_hate'] == 1)]\nsample_without_labels = train[(train['toxic'] == 0) & (train['severe_toxic'] == 0) & (train['obscene'] == 0) & (train['threat'] == 0) & (train['insult'] == 0) & (train['identity_hate'] == 0)].sample(10000)\ntrain_sample = pd.concat([with_labels, sample_without_labels]).sample(frac=1)\ntrain_sample.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:50:43.709267Z","iopub.execute_input":"2023-12-07T15:50:43.709595Z","iopub.status.idle":"2023-12-07T15:50:43.778831Z","shell.execute_reply.started":"2023-12-07T15:50:43.709572Z","shell.execute_reply":"2023-12-07T15:50:43.777797Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(26225, 8)"},"metadata":{}}]},{"cell_type":"code","source":"train_sample.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:50:43.781545Z","iopub.execute_input":"2023-12-07T15:50:43.782117Z","iopub.status.idle":"2023-12-07T15:50:43.805156Z","shell.execute_reply.started":"2023-12-07T15:50:43.782087Z","shell.execute_reply":"2023-12-07T15:50:43.803588Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                      id                                       comment_text  \\\n55127   93466b5c40415017  \"\\n\\nHello there my name is and i was wonderin...   \n17934   2f5a80474f66d0cc  What?? Your told me I could argue that the boo...   \n100604  1a7fe52027af85c8  Oh, guess what? This is all fucking pointless....   \n109461  4973127e15435e24  here's your fucking citation  \\n\\nhttps://mobi...   \n24791   419638cd6fa729bf  OMG WTF \\n\\nTook MY NAME OUT, WTH??!?!?!?  ......   \n\n        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n55127       0             0        0       0       0              0  \n17934       0             0        0       0       0              0  \n100604      1             0        1       0       0              0  \n109461      1             0        1       0       0              0  \n24791       1             0        1       0       1              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>55127</th>\n      <td>93466b5c40415017</td>\n      <td>\"\\n\\nHello there my name is and i was wonderin...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17934</th>\n      <td>2f5a80474f66d0cc</td>\n      <td>What?? Your told me I could argue that the boo...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>100604</th>\n      <td>1a7fe52027af85c8</td>\n      <td>Oh, guess what? This is all fucking pointless....</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>109461</th>\n      <td>4973127e15435e24</td>\n      <td>here's your fucking citation  \\n\\nhttps://mobi...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24791</th>\n      <td>419638cd6fa729bf</td>\n      <td>OMG WTF \\n\\nTook MY NAME OUT, WTH??!?!?!?  ......</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_texts = [text for text in train_sample['comment_text']]","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:50:43.806831Z","iopub.execute_input":"2023-12-07T15:50:43.807348Z","iopub.status.idle":"2023-12-07T15:50:43.821433Z","shell.execute_reply.started":"2023-12-07T15:50:43.807287Z","shell.execute_reply":"2023-12-07T15:50:43.820019Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n    return cleaned_text","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:50:43.823242Z","iopub.execute_input":"2023-12-07T15:50:43.823795Z","iopub.status.idle":"2023-12-07T15:50:43.835196Z","shell.execute_reply.started":"2023-12-07T15:50:43.823748Z","shell.execute_reply":"2023-12-07T15:50:43.832959Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"cleaned_train_texts = [clean_text(text) for text in train_texts]","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:50:43.837200Z","iopub.execute_input":"2023-12-07T15:50:43.837706Z","iopub.status.idle":"2023-12-07T15:50:44.021219Z","shell.execute_reply.started":"2023-12-07T15:50:43.837664Z","shell.execute_reply":"2023-12-07T15:50:44.019198Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def tokenize_text(text):\n    words = word_tokenize(text)\n    words = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n    return ' '.join(words)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:50:44.023594Z","iopub.execute_input":"2023-12-07T15:50:44.024107Z","iopub.status.idle":"2023-12-07T15:50:44.031758Z","shell.execute_reply.started":"2023-12-07T15:50:44.024056Z","shell.execute_reply":"2023-12-07T15:50:44.030424Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:50:44.033752Z","iopub.execute_input":"2023-12-07T15:50:44.034089Z","iopub.status.idle":"2023-12-07T15:50:44.047271Z","shell.execute_reply.started":"2023-12-07T15:50:44.034061Z","shell.execute_reply":"2023-12-07T15:50:44.046405Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokenized_train_texts = [tokenize_text(text) for text in cleaned_train_texts]","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:50:44.052341Z","iopub.execute_input":"2023-12-07T15:50:44.052752Z","iopub.status.idle":"2023-12-07T15:50:52.351175Z","shell.execute_reply.started":"2023-12-07T15:50:44.052716Z","shell.execute_reply":"2023-12-07T15:50:52.350405Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer() \nX_vectorized = vectorizer.fit_transform(tokenized_train_texts)\n\ntrain_val_split = 0.9\nsplit = int(X_vectorized.shape[0]*train_val_split)\n\nX_train = X_vectorized[:split, :]\nX_test = X_vectorized[split:, :]","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:50:52.352615Z","iopub.execute_input":"2023-12-07T15:50:52.353021Z","iopub.status.idle":"2023-12-07T15:50:53.246860Z","shell.execute_reply.started":"2023-12-07T15:50:52.352987Z","shell.execute_reply":"2023-12-07T15:50:53.244876Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"Y_train = train_sample[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']][:split]\nY_test = train_sample[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']][split:]","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:50:53.248796Z","iopub.execute_input":"2023-12-07T15:50:53.249191Z","iopub.status.idle":"2023-12-07T15:50:53.258524Z","shell.execute_reply.started":"2023-12-07T15:50:53.249168Z","shell.execute_reply":"2023-12-07T15:50:53.257726Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"Y_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:50:53.259663Z","iopub.execute_input":"2023-12-07T15:50:53.260934Z","iopub.status.idle":"2023-12-07T15:50:53.280110Z","shell.execute_reply.started":"2023-12-07T15:50:53.260870Z","shell.execute_reply":"2023-12-07T15:50:53.278442Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"        toxic  severe_toxic  obscene  threat  insult  identity_hate\n55127       0             0        0       0       0              0\n17934       0             0        0       0       0              0\n100604      1             0        1       0       0              0\n109461      1             0        1       0       0              0\n24791       1             0        1       0       1              0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>55127</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17934</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>100604</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>109461</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24791</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"log_models = []\nfor col in Y_train.columns:\n    model = LogisticRegression(max_iter = 5000)\n    model.fit(X_train, Y_train[col])\n    log_models.append(model)\n    Y_pred = model.predict(X_test)\n\n    roc_auc = roc_auc_score(Y_test[col], Y_pred)\n    print(col)\n    print(f\"Roc auc score: {roc_auc}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:50:53.282268Z","iopub.execute_input":"2023-12-07T15:50:53.283373Z","iopub.status.idle":"2023-12-07T15:51:00.799479Z","shell.execute_reply.started":"2023-12-07T15:50:53.283290Z","shell.execute_reply":"2023-12-07T15:51:00.798247Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"toxic\nRoc auc score: 0.8664189318415453\nsevere_toxic\nRoc auc score: 0.5809012295635726\nobscene\nRoc auc score: 0.8187356284371211\nthreat\nRoc auc score: 0.5375\ninsult\nRoc auc score: 0.7421141469493666\nidentity_hate\nRoc auc score: 0.5871866436618289\n","output_type":"stream"}]},{"cell_type":"code","source":"log_models = []\nlog_rocs = []\nfor col in Y_train.columns:\n    best_model = None\n    best_roc_auc = 0\n    for C in [10**i for i in range(-1, 4)]:\n        model = LogisticRegression(max_iter = 1000, C = C)\n        model.fit(X_train, Y_train[col])\n        Y_pred = model.predict(X_test)\n\n        roc_auc = roc_auc_score(Y_test[col], Y_pred)\n\n        if roc_auc > best_roc_auc:\n            best_roc_auc = roc_auc\n            best_model = model\n\n        print(f\"{col}, C: {C}\")\n        print(f\"Roc auc score: {roc_auc}\")\n    log_models.append(best_model)\n    log_rocs.append(best_roc_auc)\nprint(\"\\n\" + str(np.mean(log_rocs)))","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:51:00.801188Z","iopub.execute_input":"2023-12-07T15:51:00.801568Z","iopub.status.idle":"2023-12-07T15:53:27.569683Z","shell.execute_reply.started":"2023-12-07T15:51:00.801537Z","shell.execute_reply":"2023-12-07T15:53:27.568521Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"toxic, C: 0.1\nRoc auc score: 0.8138229458031508\ntoxic, C: 1\nRoc auc score: 0.8664189318415453\ntoxic, C: 10\nRoc auc score: 0.8680326448157977\ntoxic, C: 100\nRoc auc score: 0.8563968777642306\ntoxic, C: 1000\nRoc auc score: 0.8364959119271319\nsevere_toxic, C: 0.1\nRoc auc score: 0.5248303243844387\nsevere_toxic, C: 1\nRoc auc score: 0.5809012295635726\nsevere_toxic, C: 10\nRoc auc score: 0.6049208526914244\nsevere_toxic, C: 100\nRoc auc score: 0.6082909793894796\nsevere_toxic, C: 1000\nRoc auc score: 0.5863877542535831\nobscene, C: 0.1\nRoc auc score: 0.7386059736806005\nobscene, C: 1\nRoc auc score: 0.8187356284371211\nobscene, C: 10\nRoc auc score: 0.8391906153100183\nobscene, C: 100\nRoc auc score: 0.8231898791600284\nobscene, C: 1000\nRoc auc score: 0.7941982009146187\nthreat, C: 0.1\nRoc auc score: 0.5\nthreat, C: 1\nRoc auc score: 0.5375\nthreat, C: 10\nRoc auc score: 0.5996128532713899\nthreat, C: 100\nRoc auc score: 0.61211285327139\nthreat, C: 1000\nRoc auc score: 0.5986449864498645\ninsult, C: 0.1\nRoc auc score: 0.6699937832178179\ninsult, C: 1\nRoc auc score: 0.7421141469493666\ninsult, C: 10\nRoc auc score: 0.7497933666791855\ninsult, C: 100\nRoc auc score: 0.7320531314372858\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"insult, C: 1000\nRoc auc score: 0.7003158893555032\nidentity_hate, C: 0.1\nRoc auc score: 0.5169491525423728\nidentity_hate, C: 1\nRoc auc score: 0.5871866436618289\nidentity_hate, C: 10\nRoc auc score: 0.6231266280997327\nidentity_hate, C: 100\nRoc auc score: 0.6180909367705267\nidentity_hate, C: 1000\nRoc auc score: 0.6106600358604825\n\n0.7167578479276006\n","output_type":"stream"}]},{"cell_type":"code","source":"for model, col in zip(log_models, Y_train.columns):\n    dump(model, f'LR_{col}.joblib')","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:53:27.571005Z","iopub.execute_input":"2023-12-07T15:53:27.571616Z","iopub.status.idle":"2023-12-07T15:53:27.594202Z","shell.execute_reply.started":"2023-12-07T15:53:27.571584Z","shell.execute_reply":"2023-12-07T15:53:27.593409Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"svc_models = []\nsvc_rocs = []\nfor col in Y_train.columns:\n    best_model = None\n    best_roc_auc = 0\n    for C in [10**i for i in range(-1, 4)]:\n        model = SVC(kernel='linear', max_iter = 1000, C = C)\n        model.fit(X_train, Y_train[col])\n        Y_pred = model.predict(X_test)\n\n        roc_auc = roc_auc_score(Y_test[col], Y_pred)\n\n        if roc_auc > best_roc_auc:\n            best_roc_auc = roc_auc\n            best_model = model\n\n        print(f\"{col}, C: {C}\")\n        print(f\"Roc auc score: {roc_auc}\")\n    svc_models.append(best_model)\n    svc_rocs.append(best_roc_auc)\nprint(\"\\n\" + str(np.mean(svc_rocs)))","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:53:27.599033Z","iopub.execute_input":"2023-12-07T15:53:27.601310Z","iopub.status.idle":"2023-12-07T15:56:36.953433Z","shell.execute_reply.started":"2023-12-07T15:53:27.601278Z","shell.execute_reply":"2023-12-07T15:56:36.952503Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"toxic, C: 0.1\nRoc auc score: 0.6941036720935235\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"toxic, C: 1\nRoc auc score: 0.788559372684023\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"toxic, C: 10\nRoc auc score: 0.7649543378995434\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"toxic, C: 100\nRoc auc score: 0.73865828731263\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"toxic, C: 1000\nRoc auc score: 0.7312615051758349\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"severe_toxic, C: 0.1\nRoc auc score: 0.7754955151590741\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"severe_toxic, C: 1\nRoc auc score: 0.6589792959371396\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"severe_toxic, C: 10\nRoc auc score: 0.615045523993639\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"severe_toxic, C: 100\nRoc auc score: 0.5600776402357269\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"severe_toxic, C: 1000\nRoc auc score: 0.6469460987600428\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"obscene, C: 0.1\nRoc auc score: 0.7501052612992912\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"obscene, C: 1\nRoc auc score: 0.7976708051334918\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"obscene, C: 10\nRoc auc score: 0.7600789391834167\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"obscene, C: 100\nRoc auc score: 0.7389180225001121\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"obscene, C: 1000\nRoc auc score: 0.6896604881679509\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"threat, C: 0.1\nRoc auc score: 0.5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"threat, C: 1\nRoc auc score: 0.5742257065427797\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"threat, C: 10\nRoc auc score: 0.6980642663569492\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"threat, C: 100\nRoc auc score: 0.6465156794425087\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"threat, C: 1000\nRoc auc score: 0.6703542392566783\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"insult, C: 0.1\nRoc auc score: 0.6834989245109085\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"insult, C: 1\nRoc auc score: 0.6957166086243982\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"insult, C: 10\nRoc auc score: 0.6300246395119897\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"insult, C: 100\nRoc auc score: 0.6276403541716459\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"insult, C: 1000\nRoc auc score: 0.588065983247408\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"identity_hate, C: 0.1\nRoc auc score: 0.7725954869921176\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"identity_hate, C: 1\nRoc auc score: 0.6578690077472176\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"identity_hate, C: 10\nRoc auc score: 0.6754000473629013\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"identity_hate, C: 100\nRoc auc score: 0.6510199939104842\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"identity_hate, C: 1000\nRoc auc score: 0.6509692479447884\n\n0.754683675825009\n","output_type":"stream"}]},{"cell_type":"code","source":"for model, col in zip(svc_models, Y_train.columns):\n    dump(model, f'SVC_{col}.joblib')","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:56:36.954827Z","iopub.execute_input":"2023-12-07T15:56:36.955340Z","iopub.status.idle":"2023-12-07T15:56:36.976983Z","shell.execute_reply.started":"2023-12-07T15:56:36.955289Z","shell.execute_reply":"2023-12-07T15:56:36.975564Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import os\nlog_models = {}\nfor file in os.listdir('/kaggle/working/'):\n  if \"SVC\" in file:\n    log_models[file.split('.')[0][4:]] = load('/kaggle/working/' + file)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:56:36.978538Z","iopub.execute_input":"2023-12-07T15:56:36.979074Z","iopub.status.idle":"2023-12-07T15:56:36.995709Z","shell.execute_reply.started":"2023-12-07T15:56:36.979041Z","shell.execute_reply":"2023-12-07T15:56:36.994026Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(log_models)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:56:36.997475Z","iopub.execute_input":"2023-12-07T15:56:36.997853Z","iopub.status.idle":"2023-12-07T15:56:37.009711Z","shell.execute_reply.started":"2023-12-07T15:56:36.997820Z","shell.execute_reply":"2023-12-07T15:56:37.008616Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"{'toxic': SVC(C=1, kernel='linear', max_iter=1000), 'threat': SVC(C=10, kernel='linear', max_iter=1000), 'identity_hate': SVC(C=0.1, kernel='linear', max_iter=1000), 'obscene': SVC(C=1, kernel='linear', max_iter=1000), 'insult': SVC(C=1, kernel='linear', max_iter=1000), 'severe_toxic': SVC(C=0.1, kernel='linear', max_iter=1000)}\n","output_type":"stream"}]},{"cell_type":"code","source":"vocabulary_dict = vectorizer.vocabulary_\nvectorizer2 = TfidfVectorizer(vocabulary=vocabulary_dict)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:56:37.012129Z","iopub.execute_input":"2023-12-07T15:56:37.013407Z","iopub.status.idle":"2023-12-07T15:56:37.020048Z","shell.execute_reply.started":"2023-12-07T15:56:37.013350Z","shell.execute_reply":"2023-12-07T15:56:37.018379Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"test_texts = [text for text in test['comment_text']]\ncleaned_test_texts = [clean_text(text) for text in test_texts]\ntokenized_test_texts = [tokenize_text(text) for text in cleaned_test_texts]\ntest_vector = vectorizer2.fit_transform(tokenized_test_texts)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:56:37.022942Z","iopub.execute_input":"2023-12-07T15:56:37.023384Z","iopub.status.idle":"2023-12-07T15:56:57.321692Z","shell.execute_reply.started":"2023-12-07T15:56:37.023352Z","shell.execute_reply":"2023-12-07T15:56:57.320088Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"sb = pd.read_csv(f_path + \"sample_submission.csv\")\nprint(f\"Test shape: {sb.shape}\")\nprint(f\"Test columns: {sb.columns}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:56:57.323693Z","iopub.execute_input":"2023-12-07T15:56:57.324672Z","iopub.status.idle":"2023-12-07T15:56:57.413695Z","shell.execute_reply.started":"2023-12-07T15:56:57.324626Z","shell.execute_reply":"2023-12-07T15:56:57.412271Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Test shape: (63978, 7)\nTest columns: Index(['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n       'identity_hate'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"for key, model in log_models.items():\n    sb[key] = model.predict(test_vector)\nsb.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:56:57.414786Z","iopub.execute_input":"2023-12-07T15:56:57.415044Z","iopub.status.idle":"2023-12-07T15:58:28.603414Z","shell.execute_reply.started":"2023-12-07T15:56:57.415021Z","shell.execute_reply":"2023-12-07T15:58:28.602185Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                 id  toxic  severe_toxic  obscene  threat  insult  \\\n0  0001ea8717f6de06      0             0        0       0       0   \n1  000247e83dcc1211      1             0        0       0       0   \n2  0002f87b16116a7f      0             0        0       0       0   \n3  0003e1cccfd5a40a      0             0        0       0       0   \n4  00059ace3e3e9a53      0             0        0       0       0   \n\n   identity_hate  \n0              0  \n1              0  \n2              0  \n3              0  \n4              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0001ea8717f6de06</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000247e83dcc1211</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0002f87b16116a7f</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0003e1cccfd5a40a</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00059ace3e3e9a53</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sb.to_csv(\"/kaggle/working/submit.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:58:28.605732Z","iopub.execute_input":"2023-12-07T15:58:28.606550Z","iopub.status.idle":"2023-12-07T15:58:28.726103Z","shell.execute_reply.started":"2023-12-07T15:58:28.606515Z","shell.execute_reply":"2023-12-07T15:58:28.724675Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"list(vocabulary_dict.keys())","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:58:28.728035Z","iopub.execute_input":"2023-12-07T15:58:28.728307Z","iopub.status.idle":"2023-12-07T15:58:28.752109Z","shell.execute_reply.started":"2023-12-07T15:58:28.728285Z","shell.execute_reply":"2023-12-07T15:58:28.750674Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"['hello',\n 'name',\n 'wondering',\n 'would',\n 'kind',\n 'enough',\n 'unblock',\n 'know',\n 'must',\n 'hear',\n 'cliche',\n 'im',\n 'sorry',\n 'wont',\n 'routine',\n 'alot',\n 'repeat',\n 'really',\n 'hope',\n 'automatically',\n 'become',\n 'best',\n 'friend',\n 'thankssssss',\n 'told',\n 'could',\n 'argue',\n 'book',\n 'reliable',\n 'source',\n 'selfpublished',\n 'nonacademic',\n 'reverted',\n 'explanation',\n 'woodzing',\n 'restored',\n 'reference',\n 'think',\n 'violation',\n 'editing',\n 'restrictions',\n 'anyway',\n 'report',\n 'added',\n 'information',\n 'scholarly',\n 'greatly',\n 'improved',\n 'article',\n 'oh',\n 'guess',\n 'fucking',\n 'pointless',\n 'convicted',\n 'life',\n 'without',\n 'parole',\n 'took',\n 'seconds',\n 'find',\n 'whining',\n 'bitching',\n 'teeth',\n 'gnashing',\n 'blp',\n 'never',\n 'bothered',\n 'look',\n 'see',\n 'already',\n 'gone',\n 'trial',\n 'sentence',\n 'please',\n 'put',\n 'bullshit',\n 'rest',\n 'heres',\n 'citation',\n 'happy',\n 'omg',\n 'wtf',\n 'wth',\n 'guys',\n 'suck',\n 'appropriate',\n 'talk',\n 'dipshit',\n 'come',\n 'house',\n 'stab',\n 'repeatedly',\n 'sleep',\n 'watch',\n 'bleed',\n 'death',\n 'cry',\n 'laugh',\n 'fuck',\n 'rape',\n 'kids',\n 'fenian',\n 'bogtrotting',\n 'shit',\n 'ones',\n 'love',\n 'die',\n 'cock',\n 'accident',\n 'trepens',\n 'epichal',\n 'fat',\n 'ugly',\n 'lonely',\n 'smelly',\n 'little',\n 'boy',\n 'conceit',\n 'human',\n 'isnt',\n 'right',\n 'chum',\n 'pretend',\n 'youre',\n 'liked',\n 'mean',\n 'something',\n 'value',\n 'eyes',\n 'world',\n 'reallyyoure',\n 'nothing',\n 'disappointed',\n 'stupid',\n 'stop',\n 'removing',\n 'links',\n 'pages',\n 'edit',\n 'calling',\n 'spamcommercial',\n 'totally',\n 'mad',\n 'heavily',\n 'edited',\n 'link',\n 'site',\n 'crucial',\n 'artists',\n 'crusade',\n 'fun',\n 'dont',\n 'get',\n 'liar',\n 'create',\n 'page',\n 'removed',\n 'tag',\n 'troll',\n 'kindly',\n 'us',\n 'county',\n 'entry',\n 'wikiproject',\n 'counties',\n 'standards',\n 'might',\n 'help',\n 'bleach',\n 'userbox',\n 'hi',\n 'possible',\n 'use',\n 'says',\n 'fan',\n 'series',\n 'userpage',\n 'havent',\n 'across',\n 'good',\n 'one',\n 'yet',\n 'appreciate',\n 'thanks',\n 'real',\n 'advice',\n 'dick',\n 'say',\n 'baseless',\n 'threats',\n 'rantings',\n 'line',\n 'ages',\n 'going',\n 'go',\n 'google',\n 'substantiate',\n 'claim',\n 'made',\n 'sick',\n 'way',\n 'treating',\n 'talking',\n 'insulting',\n 'pathetic',\n 'handle',\n 'substantiating',\n 'claims',\n 'make',\n 'attacking',\n 'turned',\n 'rather',\n 'focus',\n 'topic',\n 'clearly',\n 'psychological',\n 'issues',\n 'proved',\n 'nada',\n 'substantiated',\n 'firmly',\n 'stand',\n 'raised',\n 'valid',\n 'concerns',\n 'evaded',\n 'attacked',\n 'incivil',\n 'around',\n 'people',\n 'dicks',\n 'feel',\n 'free',\n 'take',\n 'anywhere',\n 'wrong',\n 'understand',\n 'hey',\n 'ned',\n 'actually',\n 'work',\n 'encyclopedia',\n 'care',\n 'blockedunblocked',\n 'bully',\n 'course',\n 'bullies',\n 'hate',\n 'called',\n 'anonymous',\n 'user',\n 'threatening',\n 'nawlinwiki',\n 'terrorist',\n 'pedophile',\n 'anybody',\n 'shes',\n 'voted',\n 'delete',\n 'first',\n 'hasnt',\n 'given',\n 'reasons',\n 'block',\n 'yeah',\n 'believe',\n 'interests',\n 'publics',\n 'mind',\n 'somebody',\n 'wikipedia',\n 'takes',\n 'serious',\n 'idea',\n 'lecture',\n 'whats',\n 'song',\n 'cretin',\n 'alrighty',\n 'fy',\n 'punk',\n 'vidgmr',\n 'homie',\n 'due',\n 'faggot',\n 'named',\n 'klptyzm',\n 'philippe',\n 'servaty',\n 'explain',\n 'vandalized',\n 'everything',\n 'referenced',\n 'secondary',\n 'citations',\n 'send',\n 'message',\n 'warn',\n 'vandal',\n 'blocked',\n 'bnp',\n 'arent',\n 'fascist',\n 'trolling',\n 'thank',\n 'question',\n 'someone',\n 'placed',\n 'anthonys',\n 'inappropriately',\n 'early',\n 'paragraph',\n 'place',\n 'lucretia',\n 'mott',\n 'corrected',\n 'error',\n 'needs',\n 'sitush',\n 'better',\n 'jatt',\n 'sikhs',\n 'aresee',\n 'like',\n 'random',\n 'articles',\n 'wikkepedia',\n 'iv',\n 'got',\n 'presented',\n 'true',\n 'view',\n 'jatts',\n 'try',\n 'saying',\n 'shudra',\n 'face',\n 'last',\n 'words',\n 'thereatning',\n 'telling',\n 'truth',\n 'visit',\n 'punjab',\n 'lifetime',\n 'salle',\n 'harami',\n 'karar',\n 'banye',\n 'tujhe',\n 'kuch',\n 'ni',\n 'pata',\n 'zada',\n 'na',\n 'bol',\n 'sala',\n 'wikepedia',\n 'pe',\n 'batha',\n 'writer',\n 'ban',\n 'raha',\n 'hai',\n 'cause',\n 'dumband',\n 'stay',\n 'dumb',\n 'email',\n 'retard',\n 'deleting',\n 'post',\n 'quit',\n 'sending',\n 'sandbox',\n 'warnings',\n 'kristof',\n 'problem',\n 'lag',\n 'old',\n 'ukrainian',\n 'orthography',\n 'since',\n 'changed',\n 'similar',\n 'case',\n 'existed',\n 'belarus',\n 'much',\n 'amplified',\n 'changes',\n 'subsequent',\n 'orthographic',\n 'reforms',\n 'noticeable',\n 'affected',\n 'whole',\n 'cities',\n 'spelled',\n 'example',\n 'minsk',\n 'mensk',\n 'fact',\n 'reason',\n 'two',\n 'versions',\n 'belarusian',\n 'edition',\n 'uses',\n 'official',\n 'adopted',\n 'version',\n 'language',\n 'happened',\n 'lesser',\n 'extent',\n 'eg',\n 'rivne',\n 'became',\n 'rovno',\n 'luhanske',\n 'luhansk',\n 'konotip',\n 'konotop',\n 'city',\n 'far',\n 'aware',\n 'reversed',\n 'falls',\n 'sufficient',\n 'differences',\n 'dialects',\n 'compare',\n 'western',\n 'central',\n 'vivid',\n 'british',\n 'american',\n 'english',\n 'cases',\n 'locals',\n 'volhynian',\n 'dialect',\n 'pronounces',\n 'whilst',\n 'somewhere',\n 'poltava',\n 'seems',\n 'mukhachevo',\n 'used',\n 'entirely',\n 'nationwide',\n 'silly',\n 'government',\n 'spellings',\n 'sevatopil',\n 'outright',\n 'even',\n 'classic',\n 'pil',\n 'originates',\n 'connotation',\n 'field',\n 'ternopil',\n 'pol',\n 'comes',\n 'greek',\n 'root',\n 'sevastopol',\n 'stick',\n 'mukachevo',\n 'leave',\n 'archaic',\n 'spelling',\n 'belongs',\n 'history',\n 'claiming',\n 'pick',\n 'choose',\n 'opinions',\n 'insert',\n 'inserting',\n 'decausa',\n 'pissing',\n 'provided',\n 'many',\n 'different',\n 'sources',\n 'didnt',\n 'kurdistanica',\n 'anytime',\n 'basically',\n 'said',\n 'unacceptable',\n 'false',\n 'wanted',\n 'deny',\n 'felt',\n 'kurdish',\n 'almost',\n 'regard',\n 'decided',\n 'relevant',\n 'otherwise',\n 'tell',\n 'born',\n 'yesterday',\n 'wasnt',\n 'proposal',\n 'taking',\n 'propsal',\n 'mine',\n 'supporting',\n 'lift',\n 'term',\n 'iranian',\n 'kurds',\n 'however',\n 'let',\n 'soon',\n 'posted',\n 'douchebag',\n 'write',\n 'nonsense',\n 'anyone',\n 'yes',\n 'agree',\n 'disagree',\n 'suggest',\n 'biased',\n 'rude',\n 'la',\n 'busy',\n 'hasbara',\n 'cocksuckers',\n 'fully',\n 'verified',\n 'facts',\n 'bunch',\n 'racists',\n 'killers',\n 'thieves',\n 'hell',\n 'vandalize',\n 'whenever',\n 'want',\n 'another',\n 'specific',\n 'genetic',\n 'explanations',\n 'wrn',\n 'written',\n 'support',\n 'often',\n 'cite',\n 'several',\n 'lines',\n 'evidence',\n 'interpret',\n 'partly',\n 'group',\n 'iq',\n 'blackwhiteeast',\n 'asian',\n 'reaction',\n 'time',\n 'brain',\n 'size',\n 'observed',\n 'worldwide',\n 'range',\n 'cultures',\n 'environments',\n 'united',\n 'states',\n 'significant',\n 'blackwhite',\n 'observable',\n 'every',\n 'age',\n 'years',\n 'within',\n 'occupation',\n 'socioeconomic',\n 'level',\n 'tested',\n 'region',\n 'country',\n 'invention',\n 'ability',\n 'jensen',\n 'argued',\n 'magnitude',\n 'race',\n 'subtests',\n 'correlate',\n 'measures',\n 'also',\n 'correlates',\n 'findings',\n 'biological',\n 'rising',\n 'heritability',\n 'races',\n 'studies',\n 'found',\n 'average',\n 'developed',\n 'starts',\n 'infants',\n 'rises',\n 'middle',\n 'childhood',\n 'peaks',\n 'adulthood',\n 'showing',\n 'virtual',\n 'disappearance',\n 'shared',\n 'environmental',\n 'effects',\n 'family',\n 'income',\n 'education',\n 'home',\n 'environment',\n 'siblings',\n 'partaking',\n 'suggested',\n 'difference',\n 'groups',\n 'strong',\n 'effect',\n 'account',\n 'comparisons',\n 'parents',\n 'children',\n 'finding',\n 'regression',\n 'differing',\n 'means',\n 'blacks',\n 'whites',\n 'entire',\n 'despite',\n 'matched',\n 'heritage',\n 'unaffected',\n 'status',\n 'generation',\n 'excessive',\n 'detail',\n 'essentially',\n 'recreated',\n 'rushtonjensen',\n 'arguments',\n 'allows',\n 'section',\n 'incontrovertible',\n 'based',\n 'various',\n 'references',\n 'response',\n 'npov',\n 'reported',\n 'rushton',\n 'assertions',\n 'factual',\n 'back',\n 'anything',\n 'attributed',\n 'directly',\n 'may',\n 'interpreted',\n 'undermining',\n 'hypothesis',\n 'depending',\n 'viewer',\n 'weaselly',\n 'four',\n 'points',\n 'comments',\n 'stub',\n 'sucks',\n 'major',\n 'museum',\n 'cant',\n 'images',\n 'vehicles',\n 'including',\n 'tank',\n 'david',\n 'cerny',\n 'painted',\n 'pink',\n 'pictures',\n 'others',\n 'bolagne',\n 'bbolange',\n 'second',\n 'blocking',\n 'reliably',\n 'sourced',\n 'criticism',\n 'always',\n 'forcing',\n 'bottom',\n 'allow',\n 'highly',\n 'person',\n 'communist',\n 'taken',\n 'outside',\n 'shot',\n 'traitor',\n 'origin',\n 'national',\n 'identities',\n 'hxseek',\n 'things',\n 'keep',\n 'running',\n 'conflicts',\n 'croatian',\n 'nationalists',\n 'seem',\n 'persistent',\n 'reiterating',\n 'origins',\n 'nation',\n 'identity',\n 'annoying',\n 'losing',\n 'dedicate',\n 'productive',\n 'id',\n 'summarized',\n 'easily',\n 'invoked',\n 'discussions',\n 'wee',\n 'need',\n 'european',\n 'specifically',\n 'deal',\n 'modernday',\n 'couldnt',\n 'discuss',\n 'related',\n 'usually',\n 'dispersed',\n 'among',\n 'disparate',\n 'sections',\n 'unrelated',\n 'inserted',\n 'subtopic',\n 'inside',\n 'template',\n 'summarize',\n 'conclusions',\n 'fines',\n 'great',\n 'boook',\n 'nazis',\n 'fought',\n 'everytime',\n 'thou',\n 'shalt',\n 'ravished',\n 'thy',\n 'buttocks',\n 'sure',\n 'hurtin',\n 'nlu',\n 'wuuld',\n 'nice',\n 'arse',\n 'redirect',\n 'talkrobert',\n 'johnston',\n 'vc',\n 'well',\n 'grinning',\n 'turd',\n 'licking',\n 'cunt',\n 'buggerize',\n 'traffic',\n 'cone',\n 'doctor',\n 'nick',\n 'ps',\n 'reverting',\n 'correct',\n 'loving',\n 'wikis',\n 'dirty',\n 'scrot',\n 'badgering',\n 'monster',\n 'red',\n 'dress',\n 'mirror',\n 'dad',\n 'thusly',\n 'trauma',\n 'urself',\n 'mmmkk',\n 'forums',\n 'allowed',\n 'ed',\n 'enfoce',\n 'wpel',\n 'dreamviews',\n 'add',\n 'tons',\n 'known',\n 'unpublished',\n 'ld',\n 'techniques',\n 'along',\n 'note',\n 'ass',\n 'sixty',\n 'diffrent',\n 'cocks',\n 'cum',\n 'pous',\n 'mouth',\n 'blocks',\n 'supposed',\n 'preventative',\n 'dickhead',\n 'timeout',\n 'spade',\n 'moron',\n 'ive',\n 'contributing',\n 'eight',\n 'college',\n 'shinola',\n 'police',\n 'officer',\n 'useful',\n 'cleanup',\n 'janitor',\n 'admins',\n 'stripped',\n 'rights',\n 'new',\n 'batch',\n 'brought',\n 'understands',\n 'jobs',\n 'hrafn',\n 'act',\n 'admin',\n 'wiki',\n 'authority',\n 'cares',\n 'asked',\n 'becuase',\n 'wereare',\n 'orangemarlin',\n 'deleted',\n 'purpose',\n 'hes',\n 'done',\n 'twice',\n 'theres',\n 'point',\n 'putting',\n 'whatever',\n 'waiting',\n 'til',\n 'looks',\n 'gives',\n 'continueing',\n 'gfy',\n 'man',\n 'supporters',\n 'losers',\n 'bitch',\n 'dreamtime',\n 'festival',\n 'shithead',\n 'folks',\n 'interested',\n 'favor',\n 'head',\n 'big',\n 'whiff',\n 'stank',\n 'everyone',\n 'else',\n 'selfrighteous',\n 'fucksissy',\n 'sincerely',\n 'guy',\n 'thats',\n 'fuckin',\n 'yo',\n 'mama',\n 'according',\n 'talklist',\n 'health',\n 'topics',\n 'sdsh',\n 'appears',\n 'straight',\n 'dump',\n 'index',\n 'httpcancerwebnclacuk',\n 'retarded',\n 'tab',\n 'content',\n 'solaris',\n 'film',\n 'edits',\n 'appear',\n 'vandalism',\n 'experiment',\n 'wikipediasandbox',\n 'test',\n 'ali',\n 'read',\n 'word',\n 'plot',\n 'movies',\n 'trailer',\n 'genre',\n 'movie',\n 'summary',\n 'trivial',\n 'unsupported',\n 'per',\n 'regulations',\n 'ignores',\n 'planet',\n 'serves',\n 'backdrop',\n 'contrast',\n 'lems',\n 'novel',\n 'discusses',\n 'length',\n 'mysterious',\n 'phenomena',\n 'surface',\n 'futile',\n 'attempts',\n 'neutrality',\n 'jesus',\n 'christ',\n 'full',\n 'morons',\n 'douglas',\n 'feith',\n 'brianpopfluxcom',\n 'personal',\n 'attacks',\n 'clarification',\n 'racist',\n 'unverified',\n 'ok',\n 'crystal',\n 'gail',\n 'mangum',\n 'making',\n 'frozen',\n 'lion',\n 'king',\n 'bestfrozen',\n 'excluded',\n 'psychopathic',\n 'murderers',\n 'tweaked',\n 'bit',\n 'metao',\n 'locked',\n 'registered',\n 'users',\n 'still',\n 'able',\n 'vying',\n 'state',\n 'tying',\n 'came',\n 'trying',\n 'comment',\n 'form',\n 'dominatortalkedits',\n 'manual',\n 'job',\n 'although',\n 'underscores',\n 'irritating',\n 'erasing',\n 'mf',\n ...]"},"metadata":{}}]},{"cell_type":"code","source":"with open(\"vocabulary.txt\", \"w\") as f:\n  f.write(str(list(vocabulary_dict.keys())))","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:58:28.754260Z","iopub.execute_input":"2023-12-07T15:58:28.754659Z","iopub.status.idle":"2023-12-07T15:58:28.772383Z","shell.execute_reply.started":"2023-12-07T15:58:28.754629Z","shell.execute_reply":"2023-12-07T15:58:28.771131Z"},"trusted":true},"execution_count":28,"outputs":[]}]}